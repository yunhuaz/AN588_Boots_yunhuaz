---
title: "AN588_Boots_yunhuaz"
format: html_document
editor: visual
---

## Using the "KamilarAndCooperData.csv" dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your $\beta$ coefficients (slope and intercept)

```{r}
# Setting Data up 
setwd("C:/Users/yunhu/Documents/BI588/AN588_Boots_yunhuaz")
data <- read.csv("KamilarAndCooperData.csv")
```

```{r}
lm1 <- lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = data)
summary(lm1)
```

The intercept implies that a species with a female body mass of 1 gram is predicted to have a home range of approximately 8 × 10⁻⁵ km². The slope coefficient of 1.03 means that for every 1% increase in female body mass, the home range size increases by approximately 1.03%.

## Then, use bootstrapping to sample from your data 1000 times with replacements, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each $\beta$ coefficients.

```{r}
## Loading necessary libraries
library(boot)

# Creating a function to extract coefficients from the linear model
lm_coef <- function(data, indices) {
  sampled_data <- data[indices,]
  
  # Fitting the model
  lm2 <- lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = sampled_data)
  
  # Returning the values (intercept & slope)
  return(c(
    intercept = coef(lm2)[1], # naming the output of column 1 = intercepts
    slope = coef(lm2)[2] # naming the output of column 2 = slopes
  ))
}

# Setting up bootstrap
set.seed(1) # To ensure we recieve the same results
samples <- 1000 

# Run bootstrap
bootstrap_output <- boot(
  data = data,
  R = 1000,
  statistic = lm_coef
)
bootstrap_output
```

I found a package called "boot", which allowed me to perform the bootstrap much quicker than manually coding the bootstrap as this require more lines of code. When manually coding bootstrap I would have to create a for loop to store the coefficients and manage the indices. However, by using the function boot() in boot it allows me to perform the code with a for loop. When manually coding bootstrap I would have to compute CIs and SE using quartile, while boot has functions that compute its through boot.ci.

```{r}
# Create dataframe from bootstrap results
boot_coefs <- data.frame(
  intercept = bootstrap_output$t[, 1],  
  slope = bootstrap_output$t[, 2]     
)

# View first few rows
head(boot_coefs)
```

Displayed the first 6 rows of bootstrap_output only including their intercept and slope.

```{r}
# Computing the SE of log(Body_mass_female_mean)
boot_se <- apply(bootstrap_output$t,2,sd)
boot_se
```

```{r}
# Computing the 95% CI of log(Body_mass_female_mean)
boot_ci <- boot.ci(bootstrap_output, type = "basic", index = 2)$basic[4:5]
```

```{r}
# Computing 95% CI of Intercept for dataframe
boot_ci_intercept <- boot.ci(bootstrap_output, type = "basic", index = 1)$basic[4:5]

# Format bootstrapped CIs as strings to put into df
boot_ci_formatted <- c(
  paste("(", boot_ci_intercept[1], ", ", boot_ci_intercept[2], ")"),
  paste("(", boot_ci[1], ", ", boot_ci[2], ")")
)

# Creating a dataframe to compare the regular lm and the bootstrapped lm outputs
df <- data.frame(
  LM_SE = summary(lm1)$coefficients[, "Std. Error"],
  Boot_SE = boot_se,
  LM_CI = paste("(", confint(lm1)[, 1], ", ", confint(lm1)[, 2], ")"),
  Boot_CI = boot_ci_formatted
)
df
```

-   How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in `lm()`?

    The bootstrap standard errors (Boot_SE, SE = 0.075) are slightly smaller than the standard errors estimated by the linear model (LM_SE, SE = 0.085). This suggests that the bootstrapped data has slightly less variability in data than what the linear model assumes. Therefore, in the bootstrap model and the linear model are providing similar inferences of the effect of log(Body_mass_female_mean) on log(HomeRange_km2).

-   How does the latter compare to the 95% CI estimated from your entire dataset?

    The 95% confidence intervals of the bootstrapped model are slightly smaller than the 95% confidence intervals of the linear model. The bootstrap CI has a higher lower bound and a lower upper bound. This suggest that the coefficient estimate between the bootstrapped model and linear model are relatively similar, indicating that both models provide similar inferences on the effect of log(Body_mass_female_mean) on log(HomeRange_km2).

## Extra Credit: Write a FUNCTION that takes as its arguments a dataframe, “d”, a linear model, “m” (as a character string, e.g., “logHR\~logBM”), a user-defined confidence interval level, “conf.level” (with default = 0.95), and a number of bootstrap replicates, “n” (with default = 1000). Your function should return a dataframe that includes: beta coefficient names; beta coefficients, standard errors, and upper and lower CI limits for the linear model based on your entire dataset; and mean beta coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.

```{r}
bootstrap_summary <- function(d, m, conf.level = 0.96, n = 1000) {
  # Convert string to formula
  formula <- as.formula(m)
  
  # Define the bootstrap function for lm
  boot_fn <- function(dataset, indices) {
    sample_data <- dataset[indices, ]
    fit_model <- lm(formula, data = sample_data)
    return(coef(fit_model))
  }
  
  # Run bootstrap
  boot_model <- boot(data = d, statistic = boot_fn, R = n)
  
  # Compute bootstrap means and standard errors
  boot_mean <- colMeans(boot_model$t)
  boot_se <- apply(boot_model$t, 2, sd)
  
  # Calculate percentile confidence intervals for each coefficient
  ci_intercept <- boot.ci(boot_model, type = "perc", index = 1)$percent[4:5]
  ci_slope <- boot.ci(boot_model, type = "perc", index = 2)$percent[4:5]
  
  # Build the dataframe
  boot_df <- data.frame(
  Coefficient = c("(Intercept)", "log(Body_mass_female_mean)"),
  Bootstrap_Mean = c(boot_mean[1], boot_mean[2]),
  Bootstrap_SE = c(boot_se[1], boot_se[2]),
  Bootstrap_LowerCI = c(ci_intercept[1], ci_slope[1]),
  Bootstrap_UpperCI = c(ci_intercept[2], ci_slope[2])
)
  
  return(boot_df)
}

```

## Extra Extra Credit: Graph each beta value from the linear model and its corresponding mean value, lower CI and upper CI from a bootstrap as a function of number of bootstraps from 10 to 200 by 10s. HINT: the beta value from the linear model will be the same for all bootstraps and the mean beta value may not differ that much!

```{r}
# Coeficients of lm1
lm1_coef <- coef(lm1)
value <- lm1_coef[coef_name]

print(names(lm1_coef))

# Initialize empty data frame
plot_data <- data.frame()

# For loop to iterate through the number of bootstraps
for (n in seq(10,200, by = 10)) {
    boot_df <- bootstrap_summary(data, "log(HomeRange_km2) ~ log(Body_mass_female_mean)", n = n)
  
  for (i in 1:nrow(boot_df)) {
    coef_name <- boot_df$Coefficient[i]
    value <- lm1_coef[coef_name]
    
    # Temporary df for current coeficients
    temp <- data.frame(
      Number_of_Bootstraps = rep(n, 4),
      Coefficient = rep(coef_name, 4),
      Type = c("Original", "Bootstrap Mean", "Lower CI", "Upper CI"),
      Value = c(lm1_coef[coef_name],
                boot_df$Bootstrap_Mean[i],
                boot_df$Bootstrap_LowerCI[i],
                boot_df$Bootstrap_UpperCI[i])
    )
    
    plot_data <- rbind(plot_data, temp)
  }
}

head(plot_data)
```

I am receiving an error because some confidence interval points come from extreme values within my bootstrap sample which can come from small samples in the beginning like 10 bootstraps.

```{r}
# Load the necessary library
library(ggplot2)

ggplot(plot_data, aes(x = Number_of_Bootstraps, y = Value, color = Type, linetype = Type)) +
  geom_line() +
  facet_wrap(~ Coefficient, scales = "free_y") +
  labs(
    title = "Bootstrap Estimates vs. Number of Bootstraps",
    x = "Number of Bootstraps",
    y = "Coefficient Estimate"
  )

```

## Issues

1.  When manually coding the bootstrap model, I ran into issues where the data wasn't the correct type for subsetting into a data frame within the for loop I created. This resulted in making the process inefficient with long run times. Therefore, I found the package "boot" which simplified the code and improved the performance.
2.  I had a lot of trouble implementing boot into the function and then creating the graphs for the extra credit and extra extra credit. I think it was because I was handling with multiple data types that I often got lost of which variable is what. Hence I ran into a lot of errors trying to reorganize a boot dataframe to display the outputs.
3.  I also didn't realize I misinterpreted the intercept and slope for question 1, however my peer reviewer was able to spot that and allow me to fix my mistake.
